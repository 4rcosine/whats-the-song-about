{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19626ed1",
   "metadata": {},
   "source": [
    "# Step 0: Presetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dc93af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Api key 0b6ea1d79b499b157eb950cf7b22ef0a\n",
    "!pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee876ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa9f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6654b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install typing_extensions==4.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b979af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure.ai.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup \n",
    "import urllib.parse\n",
    "import re\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7268ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61661923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token = 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\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a864c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \".\\\\canzoni.db\"\n",
    "con = sqlite3.connect(\"C:\\\\Users\\\\Giobberto\\\\source\\\\repos\\\\SongAdder\\\\SongAdder\\\\asset\\\\canzoni.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadbdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_set = {'pop','rock','metal','jazz-blues-rnb','folk-country','rap', 'techno-dance'}\n",
    "topics_set = {'war','love','lifestyle', 'friendship','delusions','drugs','party','betrayal','music','pain','death','drinking','memories', 'occult', 'violence', 'money'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold for the minimum likelihood that a label need to have in order to be pick as possible result\n",
    "min_lkl = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24835e",
   "metadata": {},
   "source": [
    "# Step 1: Dataset creation (creator side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bccba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT count(*) as ct FROM canzoni\")\n",
    "ctt = cur.fetchone()\n",
    "\n",
    "#Inserting songs (notebook side - most of the songs will be inserted by web interface)\n",
    "for i in range(1, 500 - ctt[0]):\n",
    "    print(\"Insert song title: \")\n",
    "    song_title = input()\n",
    "    print(\"Insert song artist: \")\n",
    "    song_artist = input()\n",
    "    \n",
    "    song_genre = \"none\"\n",
    "    while not set(song_genre.split(\",\")).issubset(genre_set):\n",
    "        print(\"Insert song genre: \")\n",
    "        song_genre = input()\n",
    "        if not set(song_genre.split(\",\")).issubset(genre_set):\n",
    "            print(\"Wrong genre\")\n",
    "    \n",
    "    song_themes = \"none\"\n",
    "    while not set(song_themes.split(\",\")).issubset(topics_set):\n",
    "        print(\"Insert song themes: \")\n",
    "        song_themes = input()\n",
    "        if not set(song_themes.split(\",\")).issubset(topics_set):\n",
    "            print(\"Wrong themes\")\n",
    "    \n",
    "    \n",
    "    cur.execute(\"INSERT INTO canzoni (titolo, artista, genere, topics_gt) VALUES (?, ?, ?, ?)\", [song_title, song_artist, song_genre, song_themes])\n",
    "    con.commit()\n",
    "    print(\"Song inserted successfully.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785c8d6",
   "metadata": {},
   "source": [
    "# Step 2: Retrieving of the lyrics from internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9026fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auth to GENIUS API\n",
    "x = requests.get(\"https://api.genius.com/oauth/authorize?client_id=k0ESO9Cpb6_rG64u5FZBICh9WHtB33sLQFSl2Zq34S8KxabyU6k8DgCk7gBfW7E0&redirect_uri=http://localhost.com&scope=me&state=123456&response_type=token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLyrics(title):\n",
    "    #1 Searching for the song\n",
    "    x = requests.get(\"http://api.genius.com/search?q=\" + urllib.parse.quote(title), headers={\"Authorization\" : \"Bearer epFEa7cyyaflPeIO0YWND29W2_t6hWcE15iHjFIbM1h4-g6HYWRo-XRAl324Osa7\"})\n",
    "    j_res = json.loads(x.text)\n",
    "    path = \"https://genius.com\" + j_res[\"response\"][\"hits\"][0][\"result\"][\"path\"]\n",
    "    \n",
    "    #3 GET request to the song resource\n",
    "    y = requests.get(path)\n",
    "\n",
    "    #4 Parsing the response\n",
    "    soup = BeautifulSoup(y.text)\n",
    "    \n",
    "    #5 Retrieving the lyrics\n",
    "    ee = soup.find_all(\"div\", {\"data-lyrics-container\" : \"true\"})\n",
    "\n",
    "    lyrics = \"\"\n",
    "    for x in ee:\n",
    "        x = BeautifulSoup(str(x).replace(\"<br/>\", \" \"), 'html.parser');\n",
    "        lyrics += re.sub(\"\\[.*?\\]\", \"\", x.text)\n",
    "\n",
    "    return lyrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08836e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM canzoni WHERE testo = '' or testo is null\")\n",
    "for element in cur.fetchall():\n",
    "    song = element[1] + \" \" + element[2]\n",
    "    lyrics = getLyrics(song)\n",
    "    print(\"Lyric trovata per \" + song + \". Primi versi: \" + lyrics[0:150] + \"\\n\\n\")\n",
    "    cur.execute(\"UPDATE canzoni SET testo = ? WHERE pk = ?\", [lyrics, element[0]])\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459ae18a",
   "metadata": {},
   "source": [
    "# Step 3: Evaluation score function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring 1 (Loose): the correct label appears into the (top 3) predicted labels\n",
    "def looseScore(truth_list, pred_list):\n",
    "    detail = dict()\n",
    "    total = len(truth_list)\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(0, total):\n",
    "        \n",
    "        curr_truth = truth_list[i]\n",
    "        curr_pred = pred_list[i]\n",
    "        \n",
    "        #Saving a dictionary that sums, for each main thematic, the rateo of correct previsions\n",
    "        if curr_truth + \"_tot\" not in detail:\n",
    "            detail[curr_truth + \"_tot\"] = 1\n",
    "            detail[curr_truth + \"_ok\"] = 0\n",
    "        else:\n",
    "            detail[curr_truth + \"_tot\"] += 1\n",
    "            \n",
    "        if curr_truth in curr_pred:\n",
    "            correct += 1\n",
    "            detail[curr_truth + \"_ok\"] += 1\n",
    "            \n",
    "    return correct/total, detail\n",
    "    \n",
    "#Scoring 2 (Strcit): the correct label is equal to the predicted label with the highest likelihood\n",
    "def strictScore(truth_list, pred_list):\n",
    "    detail = dict()\n",
    "    total = len(truth_list)\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(0, total):\n",
    "        \n",
    "        curr_truth = truth_list[i]\n",
    "        curr_pred = pred_list[i][0]\n",
    "        \n",
    "        #Saving a dictionary that sums, for each main thematic, the rateo of correct previsions\n",
    "        if curr_truth + \"_tot\" not in detail:\n",
    "            detail[curr_truth + \"_tot\"] = 1\n",
    "            detail[curr_truth + \"_ok\"] = 0\n",
    "        else:\n",
    "            detail[curr_truth + \"_tot\"] += 1\n",
    "        \n",
    "        if curr_truth == curr_pred:\n",
    "            correct += 1\n",
    "            detail[curr_truth + \"_ok\"] += 1\n",
    "            \n",
    "    return correct/total, detail\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb46d1",
   "metadata": {},
   "source": [
    "# Step 4: Song classification (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a547dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing training and test dataset (test dataset will be composed of the first 60 songs in the DB)\n",
    "\n",
    "#Training dataset\n",
    "data_train = { \"ids\" : [], \"lyrics\" : [], \"label\" : []}\n",
    "\n",
    "#Test dataset\n",
    "data_test = { \"ids\" : [], \"lyrics\" : [], \"label\" : []}\n",
    "\n",
    "cur.execute(\"SELECT * FROM canzoni ORDER BY pk\")\n",
    "songs = cur.fetchall()\n",
    "\n",
    "idx = 0\n",
    "for song in songs:\n",
    "    if idx >= 60:\n",
    "        data_train['ids'].append(song[0])\n",
    "        data_train['lyrics'].append(song[4])\n",
    "        data_train['label'].append(song[5])\n",
    "        \n",
    "    else:\n",
    "        data_test['ids'].append(song[0])\n",
    "        data_test['lyrics'].append(song[4])\n",
    "        data_test['label'].append(song[5])\n",
    "        \n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(data_train['lyrics'])\n",
    "X_test = vectorizer.transform(data_test['lyrics'])\n",
    "\n",
    "y_train = data_train['label']\n",
    "y_test = data_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2eda6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multi_classifier = LogisticRegression(solver='liblinear')\n",
    "multi_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = multi_classifier.predict(X_test)\n",
    "class_probabilities  = multi_classifier.predict_proba(X_test)\n",
    "\n",
    "list_pred = []\n",
    "\n",
    "# Print the predicted class and class probabilities for each instance\n",
    "for i in range(len(y_test)):\n",
    "    lwp = dict()\n",
    "    for j in range(0, 16):\n",
    "         lwp.update({multi_classifier.classes_[j] : '{:f}'.format(class_probabilities[i][j])})\n",
    "    \n",
    "    \n",
    "    lwp_sorted = sorted(lwp.items(), key=lambda x:x[1], reverse=True)\n",
    "    lwp_pure = []\n",
    "    for j in range (0, 3):\n",
    "        if float(lwp_sorted[j][1]) > min_lkl:\n",
    "            lwp_pure.append(lwp_sorted[j][0])\n",
    "    \n",
    "    #If the set of predicted labels is still empty, i take just the one with the best likelihood\n",
    "    if len(lwp_pure) == 0:\n",
    "        lwp_pure.append()\n",
    "    \n",
    "    #Writing on DB\n",
    "    cur.execute(\"UPDATE canzoni SET topics_lg = ? WHERE pk = ?\", [','.join(lwp_pure), data_test[\"ids\"][i]])\n",
    "    con.commit()\n",
    "    list_pred.append(lwp_pure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade43c92",
   "metadata": {},
   "source": [
    "# Step 5: Song classification (Zero-shot Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifies_params = [\n",
    "    (\"zero-shot-classification\", \"facebook/bart-large-mnli\", \"topics_zs_c1\"),\n",
    "    (\"zero-shot-classification\", \"MoritzLaurer/deberta-v3-base-zeroshot-v1\", \"topics_zs_c2\"),\n",
    "    (\"zero-shot-classification\", \"sileod/deberta-v3-base-tasksource-nli\", \"topics_zs_c3\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(text):\n",
    "    fhandle = open(\"classifier_log.txt\", \"a\", encoding='UTF-8')\n",
    "    print(text)\n",
    "    fhandle.write(text + \"\\n\")\n",
    "    fhandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(pipe, lyrics, categs):\n",
    "    tmp = pipe(lyrics, candidate_labels=categs)\n",
    "\n",
    "    res = dict()\n",
    "    for i in range(0, len(tmp[\"labels\"])):\n",
    "        res.update({tmp[\"labels\"][i] : tmp[\"scores\"][i]})\n",
    "\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd35b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyJob(cl_idx):\n",
    "    pipe = pipeline(classifies_params[cl_idx][0], model=classifies_params[cl_idx][1])\n",
    "    cur.execute(\"SELECT * FROM canzoni WHERE pk >= 1 and pk <= 60\")\n",
    "    songs = cur.fetchall()\n",
    "\n",
    "    #Clearing the log file (we're going to use it because classification task lasts a lot and we want to keep track of it)\n",
    "    fhandle = open(\"classifier_log.txt\", \"w\", encoding='UTF-8')\n",
    "    fhandle.write(\"\")\n",
    "    fhandle.close()\n",
    "\n",
    "    for song in songs:\n",
    "        log(\"Classifying \" + song[1] + \" in corso...\")\n",
    "\n",
    "        #Adding temporarily 'dance' to the topics. It will be collapsed into 'party' as long as its score is higher than party\n",
    "        topics_tmp = list(topics_set)\n",
    "        topics_tmp.append(\"dance\")\n",
    "        \n",
    "        #Classification: what is the song about?\n",
    "        labels = classify(pipe, song[4], topics_tmp)\n",
    "\n",
    "        if labels[\"dance\"] > labels[\"party\"]:\n",
    "            labels[\"party\"] = labels[\"dance\"]\n",
    "            \n",
    "        labels.pop(\"dance\")\n",
    "\n",
    "        #Sorting the labels by likelihood\n",
    "        labels_list = sorted(labels.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "        #Keeping only the labels that have a likelihood at least >= than the threshold min_lkl (previously declared)\n",
    "        top_topics = []\n",
    "        for i in range(0,3):\n",
    "            if labels_list[i][1] > min_lkl:\n",
    "                top_topics.append(labels_list[i][0])\n",
    "                \n",
    "        #If none of the labels is predicted with likelihood over min_lkl, i keep just the best one\n",
    "        if len(top_topics) == 0:\n",
    "            top_topics.append(labels_list[0][0])\n",
    "\n",
    "        top_topics_str = ','.join(top_topics)\n",
    "\n",
    "        cur.execute(\"UPDATE canzoni SET \" + classifies_params[cl_idx][2] + \"= ? WHERE pk = ?\", [top_topics_str, song[0]])\n",
    "        con.commit()\n",
    "        log(\" â†’ classified as \" + top_topics_str + \"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8a80a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Calling the zero-shot classifier and saving the results for each of the different training datasets\n",
    "classifyJob(0)\n",
    "log(\"Classification #1 ENDED\")\n",
    "\n",
    "classifyJob(1)\n",
    "log(\"Classification #2 ENDED\")\n",
    "\n",
    "classifyJob(2)\n",
    "log(\"Classification #3 ENDED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d1f8e",
   "metadata": {},
   "source": [
    "# Step 6: Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the print functions for the score function returns\n",
    "def printScore(cl_name, sc_loose, det_loose, sc_strict, det_strict):\n",
    "    \n",
    "    print(\"### Evaluation scores for \" + cl_name + \" ###\")\n",
    "    print(\"# Loose score: \" + '{:f}'.format(sc_loose))\n",
    "    for theme in topics_set:\n",
    "        if theme + \"_tot\" in det_loose:\n",
    "            print(theme + \": \" + str(det_loose[theme + \"_ok\"]) + \" correct over \" + str(det_loose[theme + \"_tot\"]) + \" -> \" + '{:f}'.format(det_loose[theme + \"_ok\"]/det_loose[theme + \"_tot\"]))\n",
    "    \n",
    "    print()\n",
    "    print(\"# Strict score: \" + '{:f}'.format(sc_strict))\n",
    "    for theme in topics_set:\n",
    "        if theme + \"_tot\" in det_strict:\n",
    "            print(theme + \": \" + str(det_strict[theme + \"_ok\"]) + \" correct over \" + str(det_strict[theme + \"_tot\"]) + \" -> \" + '{:f}'.format(det_strict[theme + \"_ok\"]/det_strict[theme + \"_tot\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the params for the score evaluation functions reading the results from the DB\n",
    "cur.execute(\"SELECT * FROM canzoni WHERE pk >= 1 and pk <= 60\")\n",
    "songs = cur.fetchall()\n",
    "\n",
    "truth_list = []\n",
    "lg_pred = []\n",
    "zs_pred_1 = []\n",
    "zs_pred_2 = []\n",
    "zs_pred_3 = []\n",
    "\n",
    "for song in songs:\n",
    "    truth_list.append(song[5])\n",
    "    lg_pred.append(song[6].split(\",\"))\n",
    "    zs_pred_1.append(song[7].split(\",\"))\n",
    "    zs_pred_2.append(song[8].split(\",\"))\n",
    "    zs_pred_3.append(song[9].split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b7b60",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3719ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sc_loose, lr_det_loose = looseScore(truth_list, lg_pred)\n",
    "lr_sc_strict, lr_det_strict = strictScore(truth_list, lg_pred)\n",
    "printScore(\"Logistic Regression\", lr_acc_loose, lr_det_loose, lr_acc_strict, lr_det_strict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d363a087",
   "metadata": {},
   "source": [
    "### Zero-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddfd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs1_sc_loose, zs1_det_loose = looseScore(truth_list, zs_pred_1)\n",
    "zs1_sc_strict, zs1_det_strict = strictScore(truth_list, zs_pred_1)\n",
    "printScore(\"Zero Shot #1\", zs1_sc_loose, zs1_det_loose, zs1_sc_strict, zs1_det_strict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a65605",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs2_sc_loose, zs2_det_loose = looseScore(truth_list, zs_pred_2)\n",
    "zs2_sc_strict, zs2_det_strict = strictScore(truth_list, zs_pred_2)\n",
    "printScore(\"Zero Shot #2\", zs2_sc_loose, zs2_det_loose, zs2_sc_strict, zs2_det_strict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3dcab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs3_sc_loose, zs3_det_loose = looseScore(truth_list, zs_pred_3)\n",
    "zs3_sc_strict, zs3_det_strict = strictScore(truth_list, zs_pred_3)\n",
    "printScore(\"Zero Shot #3\", zs3_sc_loose, zs3_det_loose, zs3_sc_strict, zs3_det_strict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174027a",
   "metadata": {},
   "source": [
    "# Step 7: End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad17546",
   "metadata": {},
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
